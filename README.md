# Vectra-X

**Vectra-X** is a high-performance, embedded vector search engine prototype designed to demonstrate modern C++ optimization techniques, SIMD acceleration, and efficient foreign function interfaces (FFI) with Python.

While existing libraries like Faiss or Hnswlib are production-hardened, Vectra-X serves as an architectural reference implementation. It explicitly focuses on **flat memory layouts**, **AVX2 instruction sets**, and **zero-copy Python bindings** to solve the "Two-Language Problem"—where high-level languages like Python need low-level performance without the overhead of data marshaling.

## Table of Contents
- [Purpose & Motivation](#purpose--motivation)
- [Architecture Overview](#architecture-overview)
- [Core Modules & Design](#core-modules--design)
  - [VectorStore: Flat Layouts & SIMD](#vectorstore-flat-layouts--simd)
  - [Python Bindings: The Zero-Copy Protocol](#python-bindings-the-zero-copy-protocol)
  - [HNSW Index (Architecture)](#hnsw-index-architecture)
- [Build System & Compiler Flags](#build-system--compiler-flags)
- [Installation & Usage](#installation--usage)

---

## Purpose & Motivation

The primary motivation behind Vectra-X is to bridge the gap between Python's ease of use and C++'s raw performance in data-intensive applications. Vector search (finding the "nearest neighbor" to a query vector) is computationally expensive, often requiring millions of floating-point operations per query.

This project specifically targets three performance bottlenecks common in naive implementations:
1.  **Memory Bandwidth:** Standard `vector<vector<float>>` implementations cause cache thrashing due to pointer indirection.
2.  **CPU Cycle Count:** Scalar math operations underutilize modern CPU capability.
3.  **FFI Overhead:** Copying data between Python and C++ creates unnecessary latency.

## Architecture Overview

Vectra-X is a hybrid system:

1.  **The C++ Core (`src/`, `include/`)**: A C++17 library responsible for memory management, distance calculations, and index traversal. It compiles into a shared object.
2.  **The Python Interface**: A thin wrapper generated by `pybind11` that talks to the C++ core.
3.  **The Build System**: A customized `setup.py` that auto-detects the operating system and injects the correct compiler intrinsics (e.g., `/arch:AVX2` for MSVC, `-mavx2` for GCC).

Data flows from Python (NumPy arrays) directly into the C++ memory space without duplication, processed by AVX2-accelerated kernels, and results are returned as Python objects.

## Core Modules & Design

### VectorStore: Flat Layouts & SIMD
**Files:** `include/VectorStore.hpp`, `src/VectorStore.cpp`

The `VectorStore` class is the heart of the engine. Unlike typical object-oriented designs that might model a vector as an object, `VectorStore` prioritizes **Data-Oriented Design**:

*   **Flat Memory Layout:** All vector embeddings are stored in a single, contiguous `std::vector<float>` named `data_`.
    *   *Why?* Modern CPUs fetch memory in cache lines (64 bytes). If vectors are scattered in heap memory (like a list of lists), the CPU spends cycles waiting for RAM. By flattening the data, we ensure that prefetching works effectively and spatial locality is maximized.
*   **AVX2 Optimization:** The L2 distance calculation uses Intel's AVX2 intrinsics (`_mm256_*`).
    *   *How:* Instead of subtracting floats one by one, the engine loads 8 floats into a 256-bit register, performs a parallel subtraction, and then a fused-multiply-add (FMA).
    *   *Fallback:* A scalar path is strictly maintained for correctness on older hardware/compilers, though the build system defaults to high-performance flags.
*   **Brute-Force Search:** The current implementation performs an exact k-Nearest Neighbor search by scanning the entire contiguous block, utilizing the full throughput of the SIMD pipeline.

### Python Bindings: The Zero-Copy Protocol
**File:** `src/main.cpp`

A specific challenge in Python/C++ integration is the "serialization tax"—serializing a generic Python list into a C++ array. Vectra-X eliminates this using the **Python Buffer Protocol**.

*   **Zero-Copy Access:** When functionality like `add_vector(np_array)` is called, C++ requests a `py::buffer_info` view of the NumPy array. It retrieves a raw pointer (`float*`) to the existing Python memory.
*   **Safety Validations:** To prevent segmentation faults, the bindings enforce strict contracts:
    *   **Dimension Check:** The array length must match the index dimension.
    *   **Type Check:** The data type must be `float32`.
    *   **Contiguity Check:** The array must not be a sliced view (strides must equal `sizeof(float)`).

This allows the engine to ingest data at the speed of memory bandwidth, with zero serialization overhead.

### HNSW Index (Architecture)
**File:** `include/HNSWIndex.hpp`

This module outlines the structural design for Hierarchical Navigable Small World (HNSW) graphs, the industry standard for approximate nearest neighbor search. It serves as an architectural blueprint, defining the `HnswNode` structure and the multi-layer connectivity graph concept similar to a skip list.

## Build System & Compiler Flags
**File:** `setup.py`

Cross-platform compilation for high-performance code is notoriously difficult. Vectra-X solves this with a custom `setup.py` that detects the host environment:

*   **Windows (MSVC):** Automatically applies `/O2` and `/arch:AVX2`.
*   **Linux/macOS (GCC/Clang):** Applies `-O3`, `-mavx2`, and `-mfma`.
*   **Standard:** Enforces C++17 standard compliance across all platforms.

## Installation & Usage

**Prerequisites:**
- Python 3.8+
- C++ Compiler (Visual Studio Build Tools on Windows, GCC/Clang on Linux)

**Install from source:**
```bash
pip install .
```

**Python Example:**
```python
import numpy as np
import vectrax

# Initialize store with 128 dimensions
store = vectrax.VectorStore(dim=128)

# Create a random vector (must be float32)
vec = np.random.rand(128).astype(np.float32)

# Add to store (Zero-copy transfer)
store.add_vector(id=1, vec=vec)

# Search
results = store.search(query=vec, k=1)
print(f"Nearest neighbor ID: {results[0][1]}, Distance: {results[0][0]}")
```
